Le projet étant open-source et actif, il évolue sans cesse. Cependant, le code sur lequelle nous avons travaillé est relativement stable. Nous allons voir l'utilisation de NanoXML dans le projet, le fonctionnement de JAXP, la librairie XML de Sun et enfin la solution apportée.

% -> Utilisation intensive de XML
% -> Philosophie de NanoXML et de DOM differente
% -> -> DOM : Tout est noeud
% -> -> NanoXML : Base sur les tags (elements)
\section{Étude de NanoXML}
Comme nous avons pu le voir, IzPack utilise intensément des fichiers XML pour la génération d'installateurs.
En effet, les fichiers XML présentent l'avantage d'être lisibles, écrivables à la main.
Pour traiter ces fichiers, une librairie a été utilisée, il s'agit de NanoXML.
\subsection{Le projet NanoXML}
NanoXML est une librairie Java open-source de gestion de XML.
Elle présente la particularité d'être légère (108Ko).
Il est possible, grâce à cette librairie, d'écrire ou d'analyser des fichiers XML.
Une fois le fichier parsé, on récupère en mémoire l'arbre XML qui peut alors être exploité.
Le choix de cette librairie a été fait au commencement de IzPack à cause de sa taille.
En effet, il est important que la partie installateur ne surcharge pas excessivement le logiciel à installer.
\subsection{Les différents composants de NanoXML}
On trouve différents éléments dans NanoXML.
\subsubsection{StdXMLParser}
Cette classe est l'implémentation de l'interface \verb|XMLParser| qui est un analyseur qui permet de créer un arbre logique représentant le fichier XML qui lui a été passé.
Il est systématiquement utilisé au moment de la lecture du fichier afin de récupérer l'arbre.
\subsubsection{StdXMLWriter}
Cette classe est l'implémentation de l'interface \verb|XMLWriter| qui permet d'écrire des fichiers XML.
Il reproduit, à partir d'un \verb|XMLElement|, le fichier XML correspondant.
Il n'est utilisé que pour générer un XML temporaire lors de la compilation ou pour écrire le XML d'installation automatique.
\subsubsection{XMLElement}
Le \verb|XMLElement| représente un élément logique du XML en mémoire. Par exemple :
\begin{lstlisting}[language=XML]
<root>
	<child>
		content
	</child>
</root>
\end{lstlisting}
En analysant un fichier contenant ce XML, on obtient un XMLElement nommé root qui possède un enfant, \verb|child|. Son enfant est un \verb|XMLElement| dont le contenu est ``content''.

L'arborescence du XML est donc réalisée par un ensemble de \verb|XMLElement|.
L'interface de \verb|XMLElement| permet de récupérer la liste des enfants, le contenu, rechercher un enfant par son nom, retirer un enfant, ajouter un enfant ou modifier le contenu.
Il s'agit de loin de la classe la plus utilisée.
En effet, on ne comptait pas moins de 499 utilisations au commencement de ce projet.

\subsection{Utilisation typique dans IzPack}
\subsubsection{Analyse de fichier}
L'analyse du fichier est exécutée pour récupérer le XML.
\begin{lstlisting}
StdXMLParser parser = new StdXMLParser();
parser.setBuilder(XMLBuilderFactory.createXMLBuilder());
parser.setReader(new StdXMLReader(in));
parser.setValidator(new NonValidator());
// We get the data
XMLElement data = (XMLElement) parser.parse();
\end{lstlisting}
Avec cet exemple, on crée les objets nécessaires à l'analyse d'un fichier, et on récupère dans \verb|data| la racine de l'arborescence du XML chargé en mémoire.
\subsubsection{Écriture d'un XML}
\begin{lstlisting}
XMLWriter writer = new XMLWriter(out);
...
writer.write(XMLElement);
\end{lstlisting}
Le \verb|XMLWriter| prend un OutputStream à sa construction.
On peut donc écrire un XML dans tout type de flux de sortie. 
Une fois le \verb|XMLWriter| instancié, il suffit de lui passer le \verb|XMLElement| représentant la racine de l'arborescence que l'on souhaite écrire.
\subsubsection{Utilisation de XMLElement}
La manipulation d'un \verb|XMLElement| se fait avec ces méthodes :
\begin{itemize}
	\item get/setAttribute pour gérer les attributs du noeud,
	\item get/setContent pour gérer le contenu,
	\item add/removeChild pour gérer les noeuds fils.
\end{itemize}
Voici un exemple d'utilisation :
% TODO : avoir un exemple plus clair/concis
\begin{lstlisting}
XMLElement root;
//...
Iterator<XMLElement> iter = root.getChildrenNamed("parsable").iterator();
while (iter.hasNext())
{
	XMLElement p = iter.next();
	String target = requireAttribute(p, "targetfile");
	String type = p.getAttribute("type", "plain");
	//...
}
\end{lstlisting}
\section{Étude JAXP}
JAXP, le processeur XML de Sun, respecte les normes W3C contrairement à NanoXML.
Il y a deux manières d'exploiter les XML avec JAXP, soit en utilisant l'analyseur SAX, soit en utilisant l'analyseur DOM.
\subsection{SAX}
SAX (Simple API for XML) est une API pour analyser les XML.
Cette API possède la particularité de procéder par évènement.
C'est à dire que l'analyseur va lire le fichier ligne par ligne et envoyer un évènement pour chaque élément particulier qu'il rencontre.

Des évènements sont levés dès que l'analyse rencontre des commentaires, du texte, des éléments...
L'avantage de cette API est l'utilisation mémoire faible, puisque le XML n'est pas mis en mémoire mais lu et traité au fur et à mesure, il permet de traiter sans problème les fichiers importants.
En contrepartie, le traitement et la manipulation du XML est plus difficile.
\subsection{DOM}
L'interface DOM (Document Object Model) de JAXP propose de mettre en mémoire le XML et offre une interaction basée sur des noeuds (node en anglais).
En DOM tout est noeud; les commentaires, le texte ou les éléments sont représentés par des noeuds.
Le XML est représenté par une arborescence de noeuds.
Des interfaces spécialisent ces noeuds comme \verb|Comment|, \verb|Element| ou \verb|Text|.

La manipulation des éléments du XML se fait grâce aux nodes.
Il est possible de récupérer le voisin d'un node, d'enlever ou d'ajouter un enfant et de récupérer ou de modifier le contenu.
%--------------------------------------------------------------------------
\section{Élaboration de la solution}
Notre travail a été de chercher une solution pour permettre de remplacer de NanoXML par JAXP et de l'appliquer au projet.
Cependant, il y avait plusieurs problèmes à cela.
\subsection{Les différences entre JAXP et NanoXML}
Comme nous avons vu précédemment, les deux API ne proposent pas la même approche pour le traitement des fichiers XML.
Nous avons choisi d'utiliser l'interface DOM vu que les avantages de SAX ne sont pas nécessaires et qu'il était peu concevable de traiter les XML avec SAX dans IzPack.
De plus, NanoXML et DOM ont une représentation similaire du XML (un arbre).
Nous allons donc comparer l'interface DOM et NanoXML pour déterminer la meilleure approche à prendre.
\subsubsection{Manipulation du XML}
La principale différence vient de l'élément atomique : le noeud de DOM ne représente pas la même notion que l'élément de NanoXML.
Dès lors, la manipulation des voisins, enfants, etc doit être adaptée.
\begin{lstlisting}[language=XML]
<!-- commentaire -->
<root>
	<noeud1>text</noeud1>
</root>
\end{lstlisting}
Dans ce morceau de XML, NanoXML comptera un enfant pour l'élément \verb|root| : \verb|noeud1|.
DOM comptera 3 noeuds : du texte (le retour à la ligne et la tabulation), \verb|noeud1| et à nouveau du texte (un retour à la ligne).

DOM possède néanmoins une interface dérivant de \verb|Node| : \verb|Element|, qui est très similaire à la classe \verb|XMLElement| de NanoXML.
\subsubsection{Contenu textuel du noeud}
NanoXML propose une méthode pour récupérer le contenu textuel d'un noeud : \verb|getContent()|.
DOM propose une méthode semblant équivalente : \verb|getNodeValue()|.
Cependant, le comportement de ces deux méthodes est complètement différent.
Prenons par exemple le code XML suivant :
\begin{lstlisting}[language=XML]
<testElement>
         foobar
</testElement>
\end{lstlisting}
Placé sur l'élément \verb|testElement|, \verb|getContent()| renvoie le résultat suivant :
\begin{lstlisting}
'
         foobar
'
\end{lstlisting}
La méthode \verb|getNodeValue()| renvoie \verb|null|, mais il suffit d'utiliser cette méthode sur le fils (le texte) pour avoir exactement le même résultat.
Malheureusement, le comportement de NanoXML devient erratique par exemple avec les éléments CDATA et le texte :
\begin{lstlisting}[language=XML]
<testElement>
         <![CDATA[ be <bold> ]]>
</testElement>
\end{lstlisting}
NanoXML renverra le résultat suivant, sans retour à la ligne :
\begin{lstlisting}
' be <bold> '
\end{lstlisting}
La concaténation des valeurs des fils donne, avec DOM :
\begin{lstlisting}
'
         be <bold>
'
\end{lstlisting}
On voit ici un comportement peu cohérent (NanoXML ignore dans certains cas les caractères blancs), qu'il faudra gérer.

\subsection{Solutions possibles}
Pour remplacer NanoXML, plusieurs approches étaient possibles.

\subsubsection{Remplacer les appels individuellement}
La première solution, bête et méchante, est de remplacer systématiquement les appels à NanoXML par des appels à JAXP.
Cependant, cette solution a des inconvénients évidents :
\begin{description}
\item[La duplication de la logique] Tout le code nécessaire à l'utilisation de l'analyseur ou du Node est réparti et dupliqué dans tout le programme.
C'est d'abord une infraction au principe DRY (\textit{don't repeat yourself}) et rend le code difficile à maintenir.
Les bugs sont plus difficiles à cibler et la correction doit se faire sur toutes les réplications.
\item[Les difficultés de tester la solution] Un autre problème et le test de cette solution.
Il faut en théorie passer par toutes les utilisations des appels pour tester correctement la solution. Cette contrainte est difficilement réalisable.
\item[La pénibilité de la tâche] Remplacer chacun des nombreux appels à NanoXML par un appel JAXP est très laborieux.
\end{description}
\subsubsection{Centraliser la logique de modification}
L'autre solution possible est de centraliser toute la logique de traduction dans des classes dédiées.
Ces classes vont copier les interfaces de NanoXML mais vont générer en réalité des appels à JAXP.
C'est le principe du design pattern adaptateur.

Cela présente plusieurs avantages :
\begin{description}
\item[Centralisation de la logique] Toute la logique de traduction est centralisée en un endroit. Il est facile de corriger les éventuelles erreurs.
\item[Rapidité de déploiement] L'adaptateur présente l'avantage de ne pas changer la logique d'utilisation. Les changements d'appels se résument à changer le nom de la classe et les imports.
\end{description}

\subsection{Création de l'adaptateur}
Nous avons donc choisi la solution de l'adaptateur pour notre problème. Pour cela, nous avons procédé en plusieurs étapes.

\subsection{Repérer les utilisations des classes de NanoXML}
Dans un premier temps, nous avons repérer les classes et les méthodes utilisées par IzPack.
Nous avons réduit l'utilisation de NanoXML à 3 classes : \verb|StdXMLParser|, \verb|StdXMLWriter| et \verb|XMLElement|.
\subsubsection{StdXMLParser et StdXMLWriter}
Les classes \verb|StdXMLParser| et \verb|StdXMLWriter| sont utilisées avec parcimonie.
On compte une trentaine d'utilisations pour \verb|StdXMLParser| et 8 utilisations pour \verb|StdXMLWriter|.
Modifier l'interface pour ces deux classes n'étaient pas un problème.
Nous avons créé les interfaces \verb|IXmlParser| et \verb|IXmlWriter| ainsi que leurs implémentations, réalisant les mêmes fonctionnalités avec des prototypes différents.
Ce ne sont pas des adaptateurs de NanoXML étant donné qu'elles ne recopient pas l'interface de NanoXML.
Cependant, elles permettent de simplifier l'utilisation de JAXP et de factoriser le code sur un endroit.
\subsubsection{XMLElement}
\verb|XMLElement| ne présente pas d'interface et est utilisé systématiquement quand il y a des XML à traiter.
Il était donc impensable de traiter et remplacer toutes les utilisations de XMLElement par des appels à JAXP étant donné son nombre d'utilisation.
Nous avons donc concentré nos efforts sur cette classe et appliquer le pattern adaptateur dessus.
Pour cela, nous avons suivi le procédé suivant.

Dans un premier temps, nous avons extrait l'interface de \verb|XMLElement| avec toutes les méthodes utilisées par IzPack.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.15\textwidth]{../image/sol_casInitial.png}
	\hfil
	\includegraphics[width=0.3\textwidth]{../image/sol_extractionInterface.png}
	\caption{Extraction de l'interface}
\end{figure}
Nous avons ensuite créé l'implémentation de l'adaptateur respectant l'interface.
IzPack utilise alors la même interface mais c'est notre implémentation qui est utilisée.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{../image/sol_implementation.png}
	\caption{Implémentation de l'adaptateur}
\end{figure}
Il suffit alors de supprimer NanoXML, ses utilisations ayant été remplacées par notre implémentation.
\subsection{Implémentation de Xinclude}
Avec NanoXML, la balise \verb|xinclude| permet d'inclure un fichier XML externe.
Ainsi, on peut utiliser un XML très succinct (et donc facilement lisible/compréhensible) qui inclut d'autres fichiers XML décrivant uniquement certaines parties de l'installation.
Cette fonctionnalité, absente de NanoXML, avait été mise en place en modifiant directement le code de son analyseur.

Xinclude est présente dans les normes W3C et JAXP l'intègre dans son implémentation.
Pour que JAXP prenne en compte les balises Xinclude, il faut que l'analyseur prenne en compte les espaces de nommage (namespaces) XML.
En effet, le Xinclude appartient au namespace \verb|xi|.
Il faut donc utiliser la balise \verb|<xi:include/>| au lieu de \verb|<xinclude/>|.
Le simple fait de rendre l'analyseur ``namepaceAware'' permet d'utiliser la fonctionnalité Xinclude.
\subsection{Implémentation de Xfragment}
La fonctionnalité Xfragment permet principalement d'ajouter des éléments sans racines avec Xinclude.
C'est à dire qu'au contenu du XML à ajouter, on va retirer les noeuds \verb|<xfragment>|.
Par exemple:
\begin{lstlisting}[language=XML]
<xfragment>
<root1>
	<noeud1>text</noeud1>
</root1>
<root2>
	<noeud1>text</noeud1>
</root2>
</xfragment>
\end{lstlisting}
Si ce XML est inclus, deux éléments, \verb|<root1>| et \verb|<root2>| seront ajoutés à l'emplacement du Xinclude.
Sans le xfragment, le XML ne serait pas valide (plusieurs éléments racine) et il y aurait erreur au moment de l'analyse.
Le Xfragment agit ici comme conteneur temporaire d'éléments.

Cette fonctionnalité a été rajoutée à NanoXML et il était nécessaire de la conserver.
Cependant, elle ne fait pas partie des spécifications W3C et l'analyseur n'offre pas de base cette fonctionnalité.
Il a fallut trouver une solution pour implémenter cette fonctionnalité.

\subsubsection{Première solution, manipulation du DOM}
Une première solution est de modifier le DOM obtenu après l'analyse du XML. 
Il faudrait chercher les noeuds nommés Xfragment et les supprimer.
Cependant, la suppression d'un noeud en DOM entraîne la suppression de tous les éléments qu'il contient.
Il faudrait donc au préalable sauvegarder le contenu, supprimer l'élément et restaurer le contenu sauvegardé.

\subsubsection{Deuxième solution, surcharge de l'analyseur}
Une autre solution est de procéder de la même manière que pour ce qui a été fait pour NanoXML.
C'est à dire de modifier l'analyseur pour traiter les xfragment de manière spécifique.
Cependant, cette solution, possible sous NanoXML (librairie incluse à IzPack), est difficilement réalisable sur JAXP (fourni par la JRE).
En effet, les appels de l'analyseur sont transmis vers les classes internes du JDK qui sont difficilement manipulables.
\subsubsection{Troisième solution, transformation XSLT}
La troisième solution a été proposée par Matthew Fudge, la personne ayant rajouté la gestion des Xfragment et Xinclude dans NanoXML pour IzPack.
Elle consiste à transformer l'arbre XML obtenu après l'analyse grâce à une transformation XSLT (eXtensible Stylesheet Language Transformation).

Les transformations XSLT permettent de définir des règles de modification d'un XML et se présente elles-même sous la forme d'un XML.
On peut distinguer la balise \verb|<xsl:template match="x">| qui va rechercher le pattern x dans le XML traité et va appliquer le traitement spécifié dans la balise.
Parmi les traitements possibles, il est possible de faire des boucles avec \verb|<xsl:for-each>|, du trie avec \verb|<xsl:sort>|, créer des conditions avec \verb|<xsl:if>|, etc...

Elles permettent de modifier facilement des XML de manière simple et conviennent parfaitement à notre problème.
La feuille de style utilisée est la suivante :
\begin{lstlisting}[language=XML]
<xsl:stylesheet 
	xmlns:xsl='http://www.w3.org/1999/XSL/Transform' version='1.0'>
    <!-- tous les elements -->
    <xsl:template match="*">
        <xsl:copy>
            <xsl:copy-of select="@*"/>
            <xsl:apply-templates/>
        </xsl:copy>
    </xsl:template>

    <!-- les elements xfragment -->
    <xsl:template match="xfragment">
        <xsl:apply-templates/>
    </xsl:template>
</xsl:stylesheet>
\end{lstlisting}

La règle appliquée sur un élément est la plus spécifique.
Ici, pour tout les éléments, on recopie l'élément.
Dans le cas du xfragment, on omet la copie.
Au final, le xfragment est supprimé du XML ce qui est le but recherché.
\subsection{Numéro de ligne}
Une fonctionnalité de NanoXML est la gestion des numéros de lignes.
Lorsqu'une incohérence est détectée dans un XML lu, IzPack prévient l'utilisateur de l'erreur, et indique le numéro de la ligne responsable dans le XML.

Du point de vue de DOM, les numéros de lignes n'ont pas de signification : une fois le fichier XML parsé, seul l'arbre DOM construit en mémoire importe.
Cet arbre, réécrit dans un fichier ne correspondra pas forcément (pour les numéros de lignes, l'indentation, etc) au fichier de départ, sans parler des ajouts/suppressions/modifications de noeuds.

Au contraire, pour SAX, les numéros de lignes sont obtenus facilement.
Dans ce cas là, il est utile de savoir à quel endroit on se trouve dans le document.

Afin d'obtenir les numéros de ligne dans un arbre DOM, les deux points de vue ont été utilisés grâce à un \verb|Transformer|.
Cet objet permet (entre autre) d'utiliser un analyseur SAX pour remplir un arbre DOM.
Lors de l'analyse SAX, on retient les numéros de lignes qui seront ajoutés aux bons éléments du DOM.
Ce nombre est stocké dans les ``user data'' qui ajoutés dans la version 3  de DOM pour stocker diverses informations supplémentaires dans un noeud.

\section{Application et tests}
Une fois la solution réalisée, nous l'avons soumis à un certain nombre de tests afin de la vérifier.
\subsection{Tests}
Afin d'avoir un comportement le plus fidèle possible à celui de NanoXML et d'assurer la fiabilité de la solution, de nombreux tests unitaires ont été écrits.
\subsubsection{Test unitaires de comparaison}
La solution a d'abord été élaborée de manière isolée.
Un projet indépendant contenant NanoXML à été créé.
C'est sur ce projet que nous avons travaillé et développé notre adaptateur.
Nous avons alors réalisé une batterie de tests couvrant toutes les méthodes de l'interface extraites et de très nombreux cas.
Ces tests unitaires effectuent des actions identiques avec notre adaptateur et NanoXML, et comparent les résultats.

Prenons l'exemple de la méthode \verb|getName()|. Le même fichier XML est parsé par les 2 librairies.
Un parcours récursif de l'arbre XML est effectué sur les 2 arbres en mémoire.
Pour chaque élément, on compare le résultat de la méthode \verb|getName()| sur l'élément courant : les retours doivent être toujours identiques.

Comme les méthodes de XMLElement sont souvent des récupérations d'informations de la même nature que \verb|getName()|, nous avons généralisé ce test à ces méthodes.
Pour cela, une méthode se charge de parcourir de manière récursive l'arbre et d'invoquer la méthode à tester en comparant leurs résultats.
Ceci nous a permis de nous assurer du comportement de l'adaptateur et de déceler des anomalies sur NanoXML.

En couvrant la quasi totalité des méthodes utilisées dans IzPack avec de nombreux cas d'utilisation, nous avons pu nous assurer du respect du comportement de notre adaptateur.

\subsubsection{Les tests unitaires sur Xinclude et Xfragment}
Avec l'ajout des fonctionnalités XInclude et XFragment à NanoXML, une batterie de tests unitaires a été fournie.
Nous avons donc repris ces tests et nous les avons intégrés aux tests de notre adaptateur.

\subsubsection{Les tests unitaires classiques}
Nous avons créé une batterie de tests unitaires classiques pour notre adaptateur.
Ils s'assurent entre autre que l'analyse, l'exploitation de l'arbre en mémoire et l'écriture du XML se font correctement.

\subsection{Intégration à IzPack}
L'intégration à IzPack de notre travail fut relativement aisée : les objets de NanoXML ont été remplacés par ceux de notre adaptateur.
Les appels n'ont quasiment pas été changés, les méthodes exposées dans les deux cas étant les mêmes grâce à l'adaptateur.
Cette intégration effectuée, nous avons pu commencer les tests sur application.
\subsubsection{Tests fonctionnels}
Une phase de tests fonctionnels a été réalisée pour tester l'intégrité de l'application après l'intégration de notre solution.
Ces tests sont des tests manuels sur les installateurs générés par IzPack.
Nous avons donc testé dans un premier temps l'application d'exemple fournie par IzPack.
Ces tests ont permis de faire ressortir quelques problèmes que nous avons pu régler rapidement.

Suite à cela, nous avons essayé de générer et lancer un installateur plus conséquent.
Nous avons pour cela utilisé l'installateur de Glassfish.
La génération et l'installation de Glassfish se sont déroulées sans problème.
\subsubsection{Profiling}
Après la phase d'implémentation et de test, nous avons pu commencer une phase d'optimisation.
En utilisant YourKit, nous avons essayé de détecter les méthodes chronophages lors d'une installation et les modifier éventuellement.

Pour profiler l'application avec yourkit, il faut placer la librairie de yourkit dans le PATH.
Une fois cette opération réalisée, il suffit de lancer l'application à profiler avec l'option \verb|-agentlib:yjpagent|.
Il est alors possible de connecter le profiler à l'application et de lancer le profiling.

Le profiling lancé, nous utilisons l'application normalement.
A la fin de l'exécution, une image de l'exécution (snapshot) est enregistrée et peut être analysée après.
Cette image comporte toutes les informations du profiling comme la trace des appels, le temps passé dans chaque méthode, le nombre d'appels aux méthodes, l'utilisation de la mémoire et du garbage collector à chaque moment de l'exécution...
Nous avons profilé deux versions de l'installateur de Glassfish : l'une a été générée avec la version 4.2.1 de IzPack et l'autre avec la dernière version construite à partir du dépôt et comportant nos modifications.

Par exemple, il est possible de rechercher tout les appels à l'objet XMLElementImpl de notre adaptateur pour voir les différentes méthodes utilisées. Sur la figure~\ref{fig:yourkitXmlElement}, on peut voir que la méthode \verb|getAttribute()| est utilisée majoritairement.
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{../image/yourkitXmlElement.png}
	\caption{Trace des appels au XMLElement}
	\label{fig:yourkitXmlElement}
\end{figure}

On peut également comparer deux snapshots et obtenir la différence dans les temps d'exécution et les appels.
Sur la figure~\ref{fig:yourkitComparaison}, nous comparons les deux installateurs et filtrons les appels aux XMLElement.
On voit apparaître le XMLElement de NanoXML pour la version 4.2.1 et le XMLElementImpl de notre adaptateur.
On voit que les performances entre les deux sont sensiblement les mêmes, les gains possibles sont relativement faibles et peu d'optimisation ont été réalisées.
\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{../image/yourkitComparaison.png}
	\caption{Comparaison entre deux snapshots}
	\label{fig:yourkitComparaison}
\end{figure}

%-------------------------------------------------------
\section{Résultats}
Le principal but de notre projet a été de pouvoir abandonner NanoXML ce qui est chose faite.
De plus, l'intégration de notre solution a apporté un certain nombres d'avantages.
\subsection{Diminution de la taille des installateurs}
Tout d'abord, l'abandon de NanoXML diminue la taille de IzPack et des installateurs générés car cette librairie n'a plus besoin d'être présente dans les installateurs.
NanoXML pèse, une fois compilé, 116Ko.
Notre adaptateur pèse 44Ko.
Chaque installateur généré par IzPack perdra donc 72Ko.
Ce chiffre peut paraître faible mais si l'installateur est téléchargé 25000 fois sur le site officiel, presque 1800 Mo de bande passante sont économisés.
\subsection{Support de fonctionnalités XML}
Outre le fait d'avoir un analyseur plus fiable et récent, un certain nombre de nouveautés a été apportée.
\subsubsection{Support de la DTD}
Désormais les DTD (document de validation d'un XML) sont pris en charge.
\subsubsection{Support natif de Xinclude}
De plus, l'inclusion de fichiers XML dans d'autres est supporté nativement, sans avoir à modifier le code de l'analyseur.
\subsection{Intégration dans la branche principale}
Régulièrement, nous synchronisions notre dépôt avec la branche principale pour prendre en compte les modifications qui ont été réalisées sur IzPack.
Cette synchronisation se passait généralement sans encombre grâce à Git, excepté quand les modifications concernaient la manipulation de XML et que les fichiers étaient conséquents (>3000 lignes).

Cette synchronisation régulière était en vue de préparer la fusion avec la branche principale.
Ainsi, une fois notre solution achevée et testée, Julien Ponge a extrait un patch qui a été soumis à la communauté des développeurs d'IzPack.
Après quoi, les modifications ont été portées sur la branche principale et seront disponibles pour la prochaines version d'IzPack, la 4.3.

% -------------------------------------------------------------------------
\section{Au delà du sujet}
Une fois l'objectif du projet atteint, nous avons décidé d'accepter l'offre de Julien Ponge en devenant contributeurs officiels du projet.
Grâce à ce titre, nous bénéficions d'accès privilégiés pour le projet, notament un accès développeur sur le dépôt subversion et un compte sur Codehaus.
\subsection{Suivi de nos apports}
Notre solution étant intégrée, il est possible que des bugs subsistent dans notre implémentation ou qu'une mauvaise interprétation de notre part mène à un comportement inattendu.
Le statut de développeur nous permet de suivre et de corriger les problèmes rencontrés par la communauté IzPack.
\subsubsection{Système de suivi de bugs, Jira}
L'évolution du projet peut être suivie via Jira.
Les anomalies, lacunes et améliorations possibles font chacunes l'objet d'un ticket.
Jira permet alors de suivre et de modifier les tickets avec un workflow similaire à LightHouse.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{../image/jira.png}
	\caption{Dashboard Jira}
\end{figure}
\subsubsection{Tests corrigés}
Nous avons par exemple corrigé des tests unitaires sur les numéros de ligne échouant.
Les tests de la classe conditionsTest échouaient également à cause de l'utilisation incorrecte de notre adaptateur.
\subsubsection{Rectification sur une interprétation}
Un problème est apparu lors de l'utilisation du Xinclude.
Ce problème a été notifié par un développeur utilisant la version de développement et donc ayant récupéré nos modifications.

Par défaut, JAXP résout le chemin de manière relative au répertoire d'exécution et c'est ce qui a été réalisée dans notre implémentation.
Or le comportement attendu, plus naturel, est de résoudre le chemin d'inclusion relativement au document incluant le XML.

\subsection{Correction de bugs}
Nous avons également corrigé plusieurs bugs recensés dans Jira.
\subsubsection{Problème lors de l'installation automatique}
Un panel, le TreePacksPanels, ne respectait pas la configuration enregistrée lors de l'installation normale.
Le problème provenait d'un oubli dans la compilation, la classe devant faire le travail automatique n'était pas présente lors de l'installation.

Un autre bug corrigé faisait quitter silencieusement (sans message d'erreur) l'installation automatique.
\subsubsection{Web installers}
IzPack possède une fonction de création d'installateurs Web.
Cette fonctionnalité permet de générer des modules d'installations qui pourront être déposés sur un serveur web avec un installateur léger contenant uniquement le noyau dur.
Les modules additionnels seront alors téléchargés s'ils sont sélectionnés.

Cette fonctionnalité présentait des lacunes dans la documentation et n'était pas fonctionnelle.
De plus, un refactoring des classes concernés est en cours de traitement.
\subsubsection{UserInputPanel}
Le panel UserInputPanel doit permettre de décider de l'alignement des éléments.
C'est a dire qu'il est possible de les placer à gauche, à droite ou au centre. Actuellement, tout les éléments sont alignés à gauche.
Le travail est en cours de réalisation mais les modifications entrent en concurrence avec le refactoring de Dennis Reil, un autre contributeur.

\subsection{Améliorations}
Outre les corrections de bugs, la qualité du code a été également améliorée.
Par exemple, le code de l'installateur automatique a été refactoré avec d'autres classes, le rendant plus lisible et améliorant sa qualité.

De même, certaines méthodes inutilisées (prévues pour des vieilles versions de Java) ont pu être supprimées.